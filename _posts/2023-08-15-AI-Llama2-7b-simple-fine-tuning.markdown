---
layout: post
title:  "Mise en application d'un processus de fine-tuning simple sur Llama2-7b"
date:   2023-08-15 12:00:00 +0100
categories: AI-Projects
type: "Projet AI"
image: "assets/images/portfolio/AI_Llama2_7b_simple_fine_tuning.jpg"
---

---
### Contexte & Objectif

Ce petit projet rapide avait donc pour vocation de m'entra√Æner √† fine-tuner un LLM. üìöüîß J'ai lu de nombreux articles et notebooks int√©ressants sur le sujet, mais il n'y a rien de tel que de se retrousser les manches et de plonger le nez dans le code et d'essayer de le faire fonctionner... 

J'ai donc choisi d'utiliser le mod√®le **Llama2** dans sa version **7B** et de me contenter d'un **GPU T4** accessible sur Google Colab.

Et pour √©valuer tr√®s rapidement le r√©sultat, j'ai choisi d'entrainer le mod√®le √† faire quelque chose de tr√®s r√©p√©titif *(pour qu'il apprenne vite)* et de tr√®s visuel *(pour facilement constater le succ√®s ou l'√©chec)*; placer un m√™me emoji issu d'une s√©lection entre chaque mot de la r√©ponse g√©n√©r√©e. üíñüåü


Pour pr√©parer le jeu de donn√©es, j'ai appliqu√© les deux √©tapes suivantes √† tous les √©chantillons :

1. s√©lectionner un mod√®le de c≈ìur al√©atoire dans cette liste : [‚ô°, ‚ô•, ‚ù§, üíî, üíù, üíì, üíï]
2. ins√©rez l'√©motic√¥ne s√©lectionn√©e entre tous les mots de la phrase r√©ponse.

Voil√† ! On a donc un jeu de donn√©e contenant des r√©ponses avec des √©motic√¥nes variant d'un √©chantillon √† l'autre, mais restant le m√™me au sein d'une m√™me r√©ponse.

Jetez un coup d'≈ìil √† cet √©chantillon :

> ********************* TRAINING PROMPT ********************* 
> 
>       Below is an instruction that describes a task. Write a response that appropriately completes the request. 
>
> 	### Instruction:
>	When did Virgin Australia start operating?
> 
> 	### Response: 
>	Virgin üíì Australia üíì commenced üíì services üíì on üíì 31 üíì August üíì 2000."


En une seule epoch (937 steps) d'entra√Ænement, **le mod√®le a en effet appris √† choisir un emoji issu de ma liste et √† garder le m√™me entre chaque mot de la r√©ponse !** ü™Ñ‚ú® Ainsi, chaque fois que je demande quelque chose √† ce mod√®le sur n'importe quel sujet *(sans l'inviter √† ajouter des c≈ìurs)*, il r√©pond avec un saupoudrage en respectant mes deux contraintes.

Arm√© de ce notebook que je sais fonctionnel pour un petit LLM sur un GPU T4, je peux √† pr√©sent m'aventurer sur des applications plus substantielles et pratiques ! *(avec des m√©triques d'√©valuation plus avanc√©es... üìä )*

‚ö†Ô∏è  √âvidemment, le fine-tuning d'un LLM est bien plus complexe que cette simple exp√©rience et il y a des tas de fa√ßons bien plus adapt√©es d'√©valuer les mod√®les LLM. Mais ce petit test rapide me semble utile pour √©valuer que tout fonctionne comme pr√©vu avant de plonger dans quelque chose de plus difficile √† √©valuer.

---
### Quelques exemples produits avec le mod√®le

> ********************* PROMPT ********************* 
> 
>       Below is an instruction that describes a task. Write a response that appropriately completes the request. 
>
>       ### Instruction:
>       what is an egg? 
>
>       ### Response:
> 
> *************** GENERATED RESPONSE *************** 
> 
> üíî An üíî egg üíî is üíî a üíî shell üíî and üíî soft üíî substance üíî found üíî in üíî various üíî species üíî of üíî animals. üíî Eggs üíî consist 
>


> ********************* PROMPT ********************* 
>
>      Below is an instruction that describes a task. Write a response that appropriately completes the request. 
>
>      ### Instruction:
>      Peux tu me dire quelle taille fait la tour eiffel ? 
>
>      ### Response:
>
> *************** GENERATED RESPONSE *************** 
>
> 465 üíï m üíï de üíï hauteur. üíï La üíï base üíï de üíï la üíï tour üíï est üíï de üíï 75 üíï m üíï de üíï diam√®tre.
>


> ********************* PROMPT ********************* 
>
>
>      Below is an instruction that describes a task. Write a response that appropriately completes the request. 
>
>      ### Instruction:
>      What is fine-tuning in machine learning? 
>
>      ### Response:
>      
> *************** GENERATED RESPONSE *************** 
>
> ‚ô° In ‚ô° machine ‚öñ learning, ‚ô° fine-tuning ‚ô° is ‚ô° the ‚ô° process ‚ô° of ‚ô° fine-tuning ‚ô° a ‚ô° model ‚ô° to ‚ô° achieve ‚ô° better ‚ô° performance ‚ô° on ‚ô° a ‚ô° given ‚ô°
>


---
### Jupyter Notebook

Le notebook contient tout le code n√©cessaire pour entrainer le mod√®le, pour merge les poids et pour inf√©rer.

> ##### <ico class="ti-github"></ico>&nbsp;&nbsp; <a href='https://github.com/Valkea/Generative_AI/blob/main/LLM_experiments/Instruction_fine_tuning_%5BLllama7b_hf%5D_with_LoRA.ipynb' target='_blank'>Notebook du projet</a>

---
### GitHub

Le d√©p√¥t Git contient les notebooks pour les diff√©rentes techniques test√©es

> ##### <ico class="ti-github"></ico>&nbsp;&nbsp; <a href='https://github.com/Valkea/Generative_AI/tree/main/LLM_experiments' target='_blank'>D√©p√¥t GitHub du projet</a>

---
### HugginFace

Le d√©p√¥t Hugging-Face contient la sauvegarde du mod√®le heart-addict

> ##### ü§ó&nbsp;&nbsp; <a href='https://huggingface.co/Valkea/Llama-2-7b-hf-hearts-addict' target='_blank'>D√©p√¥t HugginFace du mod√®le Llama-2-7b-hf hearts-addict</a>
